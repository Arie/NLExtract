# Example of process-chains for extracting Top10NL source data from GML to PostGIS.
# A Chain is a series of Components: one Input, zero or more Filters and one Output.
# The output of a Component is connected to the input of the next Component (except for
# the final Output Component, which writes to the final destination, e.g. Postgres.
#
# Currently 3 chains are executed in the following order:
# - SQL pre:  DB initialization, delete tables, create schema
# - Main ETL chain, consists of the following components
# 1. input_zip_file: reads files from input ZIP file(s)
# 2. extract_zip_file: extracts a GML file from a ZIP file
# 3. parse_gml_file: parses elements from a GML file
# 4. xml_assembler: assemble feature elements into smaller (etree) docs
# 5. transformer_xslt: transform each (etree) doc
# 6. packet_writer: writes the transformed GML document to a file
# 7. output_ogr2ogr: output using ogr2ogr, input is a transformed GML file, output can be any OGR output
# - SQL post:  remove duplicates
#
# Any substitutable values are specified in curly brackets e.g. {password}.
# Actual values can be passed as args to Stetl main.py or as arguments from a wrapper program
# like top10extract.py to etl.py. Here are the 3 chains:

[etl]
chains = input_sql_pre|schema_name_filter|output_postgres,
         input_zip_file|extract_zip_file|parse_gml_file|xml_assembler|transformer_xslt|packet_writer|output_ogr2ogr,
         input_sql_post|schema_name_filter|output_postgres

# Pre SQL file inputs to be executed
[input_sql_pre]
class = inputs.fileinput.StringFileInput
file_path = sql/drop-tables-v1.2.sql,sql/create-schema.sql

# Post SQL file inputs to be executed
[input_sql_post]
class = inputs.fileinput.StringFileInput
file_path = sql/delete-duplicates-v1.2.sql,sql/update-multiattributes-v1.2.sql

# Generic filter to substitute Python-format string values like {schema} in string
[schema_name_filter]
class = filters.stringfilter.StringSubstitutionFilter
# format args {schema} is schema name
format_args = schema:{schema}

[output_postgres]
class = outputs.dboutput.PostgresDbOutput
database = {database}
host = {host}
port = {port}
user = {user}
password = {password}
schema = {schema}

# The source input ZIP-file(s) from dir, producing 'records' with ZIP file name and inner file names
[input_zip_file]
class=inputs.fileinput.ZipFileInput
file_path = {gml_files}
filename_pattern = *.[zZ][iI][pP]
name_filter=.*\.[gG][mM][lL]

# Filter to extract a ZIP file one by one to a temporary location
[extract_zip_file]
class=filters.zipfileextractor.ZipFileExtractor
file_path = {temp_dir}/fromzip-tmp.gml

# The source input file producing cityObjectMember elements
[parse_gml_file]
class = filters.xmlelementreader.XmlElementReader
element_tags = FeatureMember

# Assembles etree docs gml:featureMember elements, each with "max_elements" elements
[xml_assembler]
class = filters.xmlassembler.XmlAssembler
max_elements = {max_features}
container_doc = <?xml version="1.0" encoding="UTF-8"?>
   <gml:FeatureCollectionT10NL
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xmlns:top10nl="http://www.kadaster.nl/schemas/imbrt/top10nl/1.2"
    xmlns:brt="http://www.kadaster.nl/schemas/imbrt/brt-alg/1.0"
    xmlns:gml="http://www.opengis.net/gml/3.2"
    xsi:schemaLocation="http://www.kadaster.nl/schemas/imbrt/top10nl/1.2 http://www.kadaster.nl/schemas/top10nl/vyyyymmdd/TOP10NL_1_2.xsd">
    </gml:FeatureCollectionT10NL >
element_container_tag = FeatureCollectionT10NL

# Transforms into simple/flat feature data (single geometry per feature type, single attrs)
[transformer_xslt]
class = filters.xsltfilter.XsltFilter
script = xsl/top10-split_v1.2.xsl

# Writes the payload of a packet as a string to a file
[packet_writer]
class = filters.packetwriter.PacketWriter
file_path = {temp_dir}/top10-tmp.gml

# The ogr2ogr command-line, may use any output here, as long as
# the input is a GML file. The "temp_file" is where etree-docs
# are saved. It has to be the same file as in the ogr2ogr command.
# TODO: find a way to use a GML-stream through stdin to ogr2ogr
[output_ogr2ogr]
class = outputs.execoutput.Ogr2OgrExecOutput
# destination format: OGR vector format name
dest_format = PostgreSQL
# destination datasource: name of datasource
dest_data_source = "PG:dbname={database} host={host} port={port} user={user} password={password} active_schema={schema}"
# layer creation options will only be added to ogr2ogr on first run
lco = -lco LAUNDER=YES -lco PRECISION=NO
# spatial_extent, translates to -spat xmin ymin xmax ymax
spatial_extent = {spatial_extent}
# gfs template
gfs_template = gfs/top10-v1.2.gfs
# miscellaneous ogr2ogr options
options = -append -gt 65536 {multi_opts} --config PG_USE_COPY YES
# cleanup input?
cleanup_input = True

# Validator for XML
[xml_schema_validator]
class = filters.xmlvalidator.XmlSchemaValidator
xsd = http://www.kadaster.nl/schemas/top10nl/vyyyymmdd/TOP10NL_1_2.xsd
enabled = False

# Below Alternative outputs for testing

# Send to stdout
[output_std]
class = outputs.standardoutput.StandardXmlOutput

[output_file]
class = outputs.fileoutput.FileOutput
file_path = test/output/top10nl-fc.gml

# Output multiple files ala Top10 file chunks GML
# Use numbering as in file expression.
[output_multifile]
class = outputs.fileoutput.MultiFileOutput
file_path = test/output/top10nl-%03d.gml

